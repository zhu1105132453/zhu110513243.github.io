<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>洛水天河</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-04-25T08:42:12.118Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>朱俊杰</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>MVP架构模式</title>
    <link href="http://yoursite.com/2019/04/25/mvp/"/>
    <id>http://yoursite.com/2019/04/25/mvp/</id>
    <published>2019-04-25T06:46:03.000Z</published>
    <updated>2019-04-25T08:42:12.118Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;一个Android
        
      
    
    </summary>
    
      <category term="开启编程之旅" scheme="http://yoursite.com/categories/%E5%BC%80%E5%90%AF%E7%BC%96%E7%A8%8B%E4%B9%8B%E6%97%85/"/>
    
    
      <category term="Java" scheme="http://yoursite.com/tags/Java/"/>
    
      <category term="RxJava2" scheme="http://yoursite.com/tags/RxJava2/"/>
    
      <category term="Retrofit2" scheme="http://yoursite.com/tags/Retrofit2/"/>
    
      <category term="MVP" scheme="http://yoursite.com/tags/MVP/"/>
    
  </entry>
  
  <entry>
    <title>学习速率</title>
    <link href="http://yoursite.com/2019/04/22/study-rate/"/>
    <id>http://yoursite.com/2019/04/22/study-rate/</id>
    <published>2019-04-22T00:21:47.000Z</published>
    <updated>2019-04-22T00:27:22.907Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;正如之前所述，梯度矢量具有方向和大小。梯度下降法算法用梯度乘以一个称为&lt;strong&gt;学习速率&lt;/strong&gt;（有时也称为&lt;strong&gt;步长&lt;/strong&gt;）的标量，以确定下一个点的位置。例如，如果梯度大小为 2.5，学习速率为
        
      
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="TensorFlow" scheme="http://yoursite.com/tags/TensorFlow/"/>
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>线性回归</title>
    <link href="http://yoursite.com/2019/04/20/SoftMax/"/>
    <id>http://yoursite.com/2019/04/20/SoftMax/</id>
    <published>2019-04-20T07:48:04.000Z</published>
    <updated>2019-04-22T00:27:38.949Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;人们早就知晓，相比凉爽的天气，蟋蟀在较为炎热的天气里鸣叫更为频繁。数十年来，专业和业余昆虫学者已将每分钟的鸣叫声和温度方面的数据编入目录。Ruth
        
      
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="TensorFlow" scheme="http://yoursite.com/tags/TensorFlow/"/>
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>损失函数</title>
    <link href="http://yoursite.com/2019/04/20/Loss-function/"/>
    <id>http://yoursite.com/2019/04/20/Loss-function/</id>
    <published>2019-04-20T07:47:50.000Z</published>
    <updated>2019-04-20T07:56:19.437Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;简单来说，&lt;strong&gt;训练&lt;/strong&gt;模型表示通过有标签样本来学习（确定）所有权重和偏差的理想值。在监督式学习中，机器学习算法通过以下方式构建模型：检查多个样本并尝试找出可最大限度地减少损失的模型；这一过程称为&lt;strong&gt;经验风险最小化&lt;/strong&gt;。&lt;/
        
      
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="TensorFlow" scheme="http://yoursite.com/tags/TensorFlow/"/>
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>降低损失：迭代方法</title>
    <link href="http://yoursite.com/2019/04/20/Iteration/"/>
    <id>http://yoursite.com/2019/04/20/Iteration/</id>
    <published>2019-04-20T07:30:27.000Z</published>
    <updated>2019-04-20T07:50:14.976Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;为了训练模型，我们需要一种可降低模型损失的方法，迭代方法（梯度下降算法）是一种广泛应用于降低损失的方法，而且使用起来简单有效。&lt;/p&gt;
&lt;p&gt;迭代学习可能会让您想到“猜数字”这种游戏。在我们的游戏中，“要猜中的数字56（假设从0-100）”就是最佳模型。刚开始，您会胡乱猜测
        
      
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="TensorFlow" scheme="http://yoursite.com/tags/TensorFlow/"/>
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>降低损失 (Reducing Loss)：梯度下降法</title>
    <link href="http://yoursite.com/2019/04/20/Gradient/"/>
    <id>http://yoursite.com/2019/04/20/Gradient/</id>
    <published>2019-04-20T07:16:27.000Z</published>
    <updated>2019-04-20T08:59:05.445Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;迭代方法图包含一个标题为“计算参数更新”的华而不实的绿框。现在，我们将用更实质的方法代替这种华而不实的算法。&lt;/p&gt;
&lt;p&gt;假设我们有时间和计算资源来计算$w_1$的所有可能值的损失。对于我们一直在研究的回归问题，所产生的损失与\(w_1\)的图形始终是凸形。换言之，图形始
        
      
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="TensorFlow" scheme="http://yoursite.com/tags/TensorFlow/"/>
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>MobileNets</title>
    <link href="http://yoursite.com/2019/04/20/MobileNets/"/>
    <id>http://yoursite.com/2019/04/20/MobileNets/</id>
    <published>2019-04-20T03:02:58.000Z</published>
    <updated>2019-04-20T03:04:42.172Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="图像识别" scheme="http://yoursite.com/categories/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/"/>
    
    
      <category term="TensorFlow" scheme="http://yoursite.com/tags/TensorFlow/"/>
    
      <category term="模型" scheme="http://yoursite.com/tags/%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>JAVA回调机制</title>
    <link href="http://yoursite.com/2019/04/16/callback/"/>
    <id>http://yoursite.com/2019/04/16/callback/</id>
    <published>2019-04-16T06:07:31.000Z</published>
    <updated>2019-04-16T07:39:31.244Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;ul&gt;
&lt;li&gt;&lt;p&gt;Class A实现接口CallBack callback ——&lt;strong&gt;背景1&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Class A中包含一个Class
        
      
    
    </summary>
    
      <category term="开启编程之旅" scheme="http://yoursite.com/categories/%E5%BC%80%E5%90%AF%E7%BC%96%E7%A8%8B%E4%B9%8B%E6%97%85/"/>
    
    
      <category term="Java" scheme="http://yoursite.com/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>盲人守护</title>
    <link href="http://yoursite.com/2019/04/13/icustoy/"/>
    <id>http://yoursite.com/2019/04/13/icustoy/</id>
    <published>2019-04-13T07:13:27.000Z</published>
    <updated>2019-04-13T07:50:56.245Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;盲人守护是一款搭配盲人眼镜、针对于用户家属可以实时掌握盲人动向的监控型社交软件，其主要目的在于加强盲人或低视力群体与其家属之间的联系，并通过盲人社区分享照顾盲人的心得、低视力群体康复的过程。以下是各个功能模块的大致展示：&lt;/p&gt;
&lt;h2 id=&quot;登录注册&quot;&gt;&lt;a
        
      
    
    </summary>
    
      <category term="盲人眼镜" scheme="http://yoursite.com/categories/%E7%9B%B2%E4%BA%BA%E7%9C%BC%E9%95%9C/"/>
    
    
      <category term="毕设" scheme="http://yoursite.com/tags/%E6%AF%95%E8%AE%BE/"/>
    
      <category term="盲人眼镜" scheme="http://yoursite.com/tags/%E7%9B%B2%E4%BA%BA%E7%9C%BC%E9%95%9C/"/>
    
  </entry>
  
  <entry>
    <title>开启编程之旅</title>
    <link href="http://yoursite.com/2019/04/13/hello-world/"/>
    <id>http://yoursite.com/2019/04/13/hello-world/</id>
    <published>2019-04-13T01:09:54.269Z</published>
    <updated>2019-04-13T07:16:42.092Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;h3 id=&quot;新建一篇文章&quot;&gt;&lt;a href=&quot;#新建一篇文章&quot; class=&quot;headerlink&quot; title=&quot;新建一篇文章&quot;&gt;&lt;/a&gt;新建一篇文章&lt;/h3&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td
        
      
    
    </summary>
    
      <category term="开启编程之旅" scheme="http://yoursite.com/categories/%E5%BC%80%E5%90%AF%E7%BC%96%E7%A8%8B%E4%B9%8B%E6%97%85/"/>
    
    
      <category term="Hexo" scheme="http://yoursite.com/tags/Hexo/"/>
    
      <category term="NexT" scheme="http://yoursite.com/tags/NexT/"/>
    
  </entry>
  
</feed>
